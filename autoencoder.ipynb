{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-05-21 12:42:59,960-WARNING-tensorflow - From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import db.mariadb as mariadb\n",
    "import os\n",
    "import MySQLdb\n",
    "import keras\n",
    "\n",
    "\n",
    "from requests_futures.sessions import FuturesSession\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logging.basicConfig(format='%(asctime)s-%(levelname)s-%(name)s - %(message)s')\n",
    "\n",
    "\n",
    "model = keras.applications.resnet50.ResNet50(include_top=False, pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shohl/.local/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size (207616860 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n",
      "/mnt/idai_cloud/dai-rom-fotothek-2007/Bestand-D-DAI-ROM-2007.5572.JPG\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0636.JPG'\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0406.JPG'\n",
      "cannot identify image file '/mnt/idai_cloud/FADatenbankabb0575/D-DAI-ROM-42.507R_56426,01.jpg'\n",
      "cannot identify image file '/mnt/idai_cloud/FADatenbankabb0575/D-DAI-ROM-56.998_002922504,02.jpg'\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0127.JPG'\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0442.JPG'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shohl/.local/lib/python3.7/site-packages/PIL/Image.py:2618: DecompressionBombWarning: Image size (124167394 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/mnt/idai_cloud/FADatenbankabb0577/D-DAI-ROM-71.623R_14505.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shohl/.local/lib/python3.7/site-packages/PIL/Image.py:2618: DecompressionBombWarning: Image size (105211691 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/mnt/idai_cloud/FADatenbankabb0122/Mal373-02_3198227.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shohl/.local/lib/python3.7/site-packages/PIL/Image.py:2618: DecompressionBombWarning: Image size (133441175 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/mnt/idai_cloud/FADatenbankabb0576/D-DAI-ROM-62.1474_130217.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shohl/.local/lib/python3.7/site-packages/PIL/Image.py:2618: DecompressionBombWarning: Image size (136193850 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "/home/shohl/.local/lib/python3.7/site-packages/PIL/Image.py:2618: DecompressionBombWarning: Image size (97257268 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0270.JPG'\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0672.JPG'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shohl/.local/lib/python3.7/site-packages/PIL/Image.py:2618: DecompressionBombWarning: Image size (144643345 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0188.JPG'\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0095.JPG'\n",
      "[Errno 2] No such file or directory: '/mnt/idai_cloud/FADatenbankabb0532/D-DAI-ROM-58.2011A_80541,50.jpg'\n",
      "[Errno 2] No such file or directory: '/mnt/idai_cloud/FADatenbankabb0024/FA4268-1_76603,3.jpg'\n",
      "cannot identify image file '/mnt/idai_cloud/FADatenbankabb0700d/Mal000-0_0002624104,03.jpg'\n",
      "cannot identify image file '/mnt/idai_cloud/dai-rom-fotothek-2003/Bestand-D-DAI-ROM-2003.0663.JPG'\n",
      "cannot identify image file '/mnt/idai_cloud/FADatenbankabb0577/D-DAI-ROM-71.623R_402540.jpg'\n",
      "(9988, 2048)\n",
      "9988\n",
      "(4993, 2048)\n",
      "4993\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from PIL.Image import DecompressionBombError\n",
    "import numpy as np\n",
    "\n",
    "# Change according to your database setup (these are the defaults, see .env file)\n",
    "\n",
    "con = mariadb.get_connection(\"127.0.0.1\", 3308, \"image_processing\", \"user\", \"user_pw\")\n",
    "\n",
    "files_batch = mariadb.get_files_data(0, 800000, con)\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Use every 100th image of the 800000\n",
    "files_batch = files_batch\n",
    "features_train = []\n",
    "features_test = []\n",
    "\n",
    "features_train_info = []\n",
    "features_test_info = []\n",
    "\n",
    "# Create training and test features\n",
    "counter = 1\n",
    "for (img_id, name, path, url) in files_batch:\n",
    "    try:\n",
    "        img = keras.preprocessing.image.load_img(path, target_size=(224, 224), grayscale=True)\n",
    "        # print(type(img))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.repeat(img_data, 3, axis=2)\n",
    "        # print(type(img_data))\n",
    "        # print(img_data.shape)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        # print(img_data.shape)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        # print(img_data.shape)\n",
    "        res_net_feature = model.predict(img_data)\n",
    "        # print(res_net_feature.shape)\n",
    "        res_net_feature = np.array(res_net_feature).flatten()\n",
    "        # print(res_net_feature.shape)\n",
    "\n",
    "        if counter % 3 == 0:\n",
    "            features_test.append(res_net_feature)\n",
    "            features_test_info.append((img_id, name, path, url))\n",
    "        else:\n",
    "            features_train.append(res_net_feature)\n",
    "            features_train_info.append((img_id, name, path, url))\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "    except DecompressionBombError as e:\n",
    "        print(e)\n",
    "        print(path)\n",
    "\n",
    "features_train = np.array(features_train)\n",
    "features_test = np.array(features_test)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(len(features_train_info))\n",
    "\n",
    "print(features_test.shape)\n",
    "print(len(features_test_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.173534\n",
      "26.796541\n",
      "0.9394322\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# We need to scale the features to values between 0 and 1, because the sigmoid layer (last autoencoder layer) \n",
    "# produces values in that range. Without scaling the original values down, the autoencoder won't be able to \n",
    "# reproduce input values > 1.\n",
    "\n",
    "print(np.max(features_train))\n",
    "print(np.max(features_test))\n",
    "\n",
    "if(np.max(features_train) > np.max(features_test)):\n",
    "    features_train_scaled = features_train / np.max(features_train)\n",
    "    features_test_scaled = features_test / np.max(features_train)\n",
    "else:\n",
    "    features_train_scaled = features_train / np.max(features_test)\n",
    "    features_test_scaled = features_test / np.max(features_test)\n",
    "\n",
    "print(np.max(features_train_scaled))\n",
    "print(np.max(features_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-21 17:50:49,376-WARNING-tensorflow - From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9988 samples, validate on 4993 samples\n",
      "Epoch 1/100000\n",
      "9988/9988 [==============================] - 9s 866us/step - loss: 3.4968 - val_loss: 1.2978\n",
      "Epoch 2/100000\n",
      "9988/9988 [==============================] - 7s 689us/step - loss: 1.2242 - val_loss: 1.2955\n",
      "Epoch 3/100000\n",
      "9988/9988 [==============================] - 8s 772us/step - loss: 1.2038 - val_loss: 1.2719\n",
      "Epoch 4/100000\n",
      "9988/9988 [==============================] - 10s 1ms/step - loss: 1.1903 - val_loss: 1.2545\n",
      "Epoch 5/100000\n",
      "9988/9988 [==============================] - 14s 1ms/step - loss: 1.1788 - val_loss: 1.2430\n",
      "Epoch 6/100000\n",
      "9988/9988 [==============================] - 8s 772us/step - loss: 1.1620 - val_loss: 1.2600\n",
      "Epoch 7/100000\n",
      "9988/9988 [==============================] - 7s 713us/step - loss: 1.1419 - val_loss: 1.3862\n",
      "Epoch 8/100000\n",
      "9988/9988 [==============================] - 7s 662us/step - loss: 1.1163 - val_loss: 1.2140\n",
      "Epoch 9/100000\n",
      "9988/9988 [==============================] - 7s 695us/step - loss: 1.0928 - val_loss: 1.1257\n",
      "Epoch 10/100000\n",
      "9988/9988 [==============================] - 7s 733us/step - loss: 1.0709 - val_loss: 1.1129\n",
      "Epoch 11/100000\n",
      "9988/9988 [==============================] - 8s 766us/step - loss: 1.0533 - val_loss: 1.0935\n",
      "Epoch 12/100000\n",
      "9988/9988 [==============================] - 7s 701us/step - loss: 1.0414 - val_loss: 1.0963\n",
      "Epoch 13/100000\n",
      "9988/9988 [==============================] - 7s 711us/step - loss: 1.0272 - val_loss: 1.0973\n",
      "Epoch 14/100000\n",
      "9988/9988 [==============================] - 7s 750us/step - loss: 1.0166 - val_loss: 1.0954\n",
      "Epoch 15/100000\n",
      "9988/9988 [==============================] - 7s 688us/step - loss: 1.0050 - val_loss: 1.1389\n",
      "Epoch 16/100000\n",
      "9988/9988 [==============================] - 7s 681us/step - loss: 0.9959 - val_loss: 1.0177\n",
      "Epoch 17/100000\n",
      "9988/9988 [==============================] - 7s 717us/step - loss: 0.9849 - val_loss: 1.0124\n",
      "Epoch 18/100000\n",
      "9988/9988 [==============================] - 7s 673us/step - loss: 0.9784 - val_loss: 1.0558\n",
      "Epoch 19/100000\n",
      "9988/9988 [==============================] - 7s 675us/step - loss: 0.9719 - val_loss: 1.0190\n",
      "Epoch 20/100000\n",
      "9988/9988 [==============================] - 7s 667us/step - loss: 0.9630 - val_loss: 0.9984\n",
      "Epoch 21/100000\n",
      "9988/9988 [==============================] - 7s 682us/step - loss: 0.9573 - val_loss: 0.9978\n",
      "Epoch 22/100000\n",
      "9988/9988 [==============================] - 7s 684us/step - loss: 0.9477 - val_loss: 0.9767\n",
      "Epoch 23/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.9436 - val_loss: 0.9918\n",
      "Epoch 24/100000\n",
      "9988/9988 [==============================] - 12s 1ms/step - loss: 0.9341 - val_loss: 0.9578\n",
      "Epoch 25/100000\n",
      "9988/9988 [==============================] - 13s 1ms/step - loss: 0.9265 - val_loss: 0.9608\n",
      "Epoch 26/100000\n",
      "9988/9988 [==============================] - 13s 1ms/step - loss: 0.9192 - val_loss: 0.9476\n",
      "Epoch 27/100000\n",
      "9988/9988 [==============================] - 18s 2ms/step - loss: 0.9109 - val_loss: 0.9335\n",
      "Epoch 28/100000\n",
      "9988/9988 [==============================] - 8s 839us/step - loss: 0.9040 - val_loss: 0.9527\n",
      "Epoch 29/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.8987 - val_loss: 0.9508\n",
      "Epoch 30/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.8905 - val_loss: 0.8985\n",
      "Epoch 31/100000\n",
      "9988/9988 [==============================] - 8s 754us/step - loss: 0.8854 - val_loss: 0.9528\n",
      "Epoch 32/100000\n",
      "9988/9988 [==============================] - 10s 1ms/step - loss: 0.8785 - val_loss: 0.9220\n",
      "Epoch 33/100000\n",
      "9988/9988 [==============================] - 8s 784us/step - loss: 0.8734 - val_loss: 0.9117\n",
      "Epoch 34/100000\n",
      "9988/9988 [==============================] - 7s 701us/step - loss: 0.8671 - val_loss: 0.8943\n",
      "Epoch 35/100000\n",
      "9988/9988 [==============================] - 7s 739us/step - loss: 0.8623 - val_loss: 0.8764\n",
      "Epoch 36/100000\n",
      "9988/9988 [==============================] - 8s 809us/step - loss: 0.8578 - val_loss: 0.8714\n",
      "Epoch 37/100000\n",
      "9988/9988 [==============================] - 8s 801us/step - loss: 0.8509 - val_loss: 0.8755\n",
      "Epoch 38/100000\n",
      "9988/9988 [==============================] - 8s 776us/step - loss: 0.8475 - val_loss: 0.8889\n",
      "Epoch 39/100000\n",
      "9988/9988 [==============================] - 7s 741us/step - loss: 0.8429 - val_loss: 0.8942\n",
      "Epoch 40/100000\n",
      "9988/9988 [==============================] - 7s 706us/step - loss: 0.8372 - val_loss: 0.8827\n",
      "Epoch 41/100000\n",
      "9988/9988 [==============================] - 8s 801us/step - loss: 0.8330 - val_loss: 0.8935\n",
      "Epoch 42/100000\n",
      "9988/9988 [==============================] - 15s 2ms/step - loss: 0.8294 - val_loss: 0.8540\n",
      "Epoch 43/100000\n",
      "9988/9988 [==============================] - 19s 2ms/step - loss: 0.8263 - val_loss: 0.8784\n",
      "Epoch 44/100000\n",
      "9988/9988 [==============================] - 14s 1ms/step - loss: 0.8221 - val_loss: 0.9049\n",
      "Epoch 45/100000\n",
      "9988/9988 [==============================] - 16s 2ms/step - loss: 0.8191 - val_loss: 0.8460\n",
      "Epoch 46/100000\n",
      "9988/9988 [==============================] - 17s 2ms/step - loss: 0.8134 - val_loss: 0.8732\n",
      "Epoch 47/100000\n",
      "9988/9988 [==============================] - 17s 2ms/step - loss: 0.8107 - val_loss: 0.8641\n",
      "Epoch 48/100000\n",
      "9988/9988 [==============================] - 9s 857us/step - loss: 0.8088 - val_loss: 0.8346\n",
      "Epoch 49/100000\n",
      "9988/9988 [==============================] - 18s 2ms/step - loss: 0.8050 - val_loss: 0.8313\n",
      "Epoch 50/100000\n",
      "9988/9988 [==============================] - 19s 2ms/step - loss: 0.8004 - val_loss: 0.8311\n",
      "Epoch 51/100000\n",
      "9988/9988 [==============================] - 10s 957us/step - loss: 0.7979 - val_loss: 0.8336\n",
      "Epoch 52/100000\n",
      "9988/9988 [==============================] - 12s 1ms/step - loss: 0.7957 - val_loss: 0.8628\n",
      "Epoch 53/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.7906 - val_loss: 0.8335\n",
      "Epoch 54/100000\n",
      "9988/9988 [==============================] - 9s 946us/step - loss: 0.7895 - val_loss: 0.8214\n",
      "Epoch 55/100000\n",
      "9988/9988 [==============================] - 7s 736us/step - loss: 0.7852 - val_loss: 0.8328\n",
      "Epoch 56/100000\n",
      "9988/9988 [==============================] - 7s 696us/step - loss: 0.7836 - val_loss: 0.8135\n",
      "Epoch 57/100000\n",
      "9988/9988 [==============================] - 8s 792us/step - loss: 0.7790 - val_loss: 0.8033\n",
      "Epoch 58/100000\n",
      "9988/9988 [==============================] - 8s 834us/step - loss: 0.7774 - val_loss: 0.7960\n",
      "Epoch 59/100000\n",
      "9988/9988 [==============================] - 13s 1ms/step - loss: 0.7725 - val_loss: 0.8302\n",
      "Epoch 60/100000\n",
      "9988/9988 [==============================] - 17s 2ms/step - loss: 0.7711 - val_loss: 0.8061\n",
      "Epoch 61/100000\n",
      "9988/9988 [==============================] - 9s 921us/step - loss: 0.7664 - val_loss: 0.8119\n",
      "Epoch 62/100000\n",
      "9988/9988 [==============================] - 12s 1ms/step - loss: 0.7655 - val_loss: 0.8161\n",
      "Epoch 63/100000\n",
      "9988/9988 [==============================] - 7s 743us/step - loss: 0.7627 - val_loss: 0.8006\n",
      "Epoch 64/100000\n",
      "9988/9988 [==============================] - 7s 711us/step - loss: 0.7608 - val_loss: 0.7982\n",
      "Epoch 65/100000\n",
      "9988/9988 [==============================] - 8s 773us/step - loss: 0.7571 - val_loss: 0.8043\n",
      "Epoch 66/100000\n",
      "9988/9988 [==============================] - 7s 726us/step - loss: 0.7544 - val_loss: 0.8059\n",
      "Epoch 67/100000\n",
      "9988/9988 [==============================] - 7s 712us/step - loss: 0.7520 - val_loss: 0.7771\n",
      "Epoch 68/100000\n",
      "9988/9988 [==============================] - 7s 727us/step - loss: 0.7495 - val_loss: 0.7877\n",
      "Epoch 69/100000\n",
      "9988/9988 [==============================] - 7s 687us/step - loss: 0.7471 - val_loss: 0.7926\n",
      "Epoch 70/100000\n",
      "9988/9988 [==============================] - 7s 701us/step - loss: 0.7450 - val_loss: 0.8063\n",
      "Epoch 71/100000\n",
      "9988/9988 [==============================] - 7s 693us/step - loss: 0.7430 - val_loss: 0.7678\n",
      "Epoch 72/100000\n",
      "9988/9988 [==============================] - 7s 735us/step - loss: 0.7412 - val_loss: 0.7557\n",
      "Epoch 73/100000\n",
      "9988/9988 [==============================] - 7s 711us/step - loss: 0.7380 - val_loss: 0.7499\n",
      "Epoch 74/100000\n",
      "9988/9988 [==============================] - 7s 697us/step - loss: 0.7358 - val_loss: 0.7639\n",
      "Epoch 75/100000\n",
      "9988/9988 [==============================] - 7s 694us/step - loss: 0.7334 - val_loss: 0.8270\n",
      "Epoch 76/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988/9988 [==============================] - 7s 698us/step - loss: 0.7307 - val_loss: 0.7812\n",
      "Epoch 77/100000\n",
      "9988/9988 [==============================] - 7s 697us/step - loss: 0.7271 - val_loss: 0.7505\n",
      "Epoch 78/100000\n",
      "9988/9988 [==============================] - 8s 794us/step - loss: 0.7257 - val_loss: 0.7566\n",
      "Epoch 79/100000\n",
      "9988/9988 [==============================] - 7s 689us/step - loss: 0.7236 - val_loss: 0.7538\n",
      "Epoch 80/100000\n",
      "9988/9988 [==============================] - 7s 698us/step - loss: 0.7222 - val_loss: 0.7607\n",
      "Epoch 81/100000\n",
      "9988/9988 [==============================] - 7s 695us/step - loss: 0.7213 - val_loss: 0.7758\n",
      "Epoch 82/100000\n",
      "9988/9988 [==============================] - 7s 742us/step - loss: 0.7192 - val_loss: 0.7841\n",
      "Epoch 83/100000\n",
      "9988/9988 [==============================] - 7s 708us/step - loss: 0.7145 - val_loss: 0.7529\n",
      "Epoch 84/100000\n",
      "9988/9988 [==============================] - 7s 684us/step - loss: 0.7137 - val_loss: 0.7817\n",
      "Epoch 85/100000\n",
      "9988/9988 [==============================] - 7s 702us/step - loss: 0.7107 - val_loss: 0.7420\n",
      "Epoch 86/100000\n",
      "9988/9988 [==============================] - 7s 700us/step - loss: 0.7104 - val_loss: 0.7241\n",
      "Epoch 87/100000\n",
      "9988/9988 [==============================] - 7s 696us/step - loss: 0.7084 - val_loss: 0.7461\n",
      "Epoch 88/100000\n",
      "9988/9988 [==============================] - 7s 667us/step - loss: 0.7079 - val_loss: 0.7388\n",
      "Epoch 89/100000\n",
      "9988/9988 [==============================] - 7s 721us/step - loss: 0.7056 - val_loss: 0.7316\n",
      "Epoch 90/100000\n",
      "9988/9988 [==============================] - 7s 676us/step - loss: 0.7025 - val_loss: 0.7348\n",
      "Epoch 91/100000\n",
      "9988/9988 [==============================] - 16s 2ms/step - loss: 0.7018 - val_loss: 0.7593\n",
      "Epoch 92/100000\n",
      "9988/9988 [==============================] - 19s 2ms/step - loss: 0.7011 - val_loss: 0.7324\n",
      "Epoch 93/100000\n",
      "9988/9988 [==============================] - 8s 754us/step - loss: 0.6987 - val_loss: 0.7309\n",
      "Epoch 94/100000\n",
      "9988/9988 [==============================] - 7s 687us/step - loss: 0.6977 - val_loss: 0.7238\n",
      "Epoch 95/100000\n",
      "9988/9988 [==============================] - 7s 678us/step - loss: 0.6946 - val_loss: 0.7338\n",
      "Epoch 96/100000\n",
      "9988/9988 [==============================] - 7s 657us/step - loss: 0.6948 - val_loss: 0.7193\n",
      "Epoch 97/100000\n",
      "9988/9988 [==============================] - 7s 652us/step - loss: 0.6931 - val_loss: 0.7262\n",
      "Epoch 98/100000\n",
      "9988/9988 [==============================] - 7s 653us/step - loss: 0.6910 - val_loss: 0.7322\n",
      "Epoch 99/100000\n",
      "9988/9988 [==============================] - 7s 651us/step - loss: 0.6906 - val_loss: 0.7163\n",
      "Epoch 100/100000\n",
      "9988/9988 [==============================] - 7s 652us/step - loss: 0.6871 - val_loss: 0.7293\n",
      "Epoch 101/100000\n",
      "9988/9988 [==============================] - 6s 650us/step - loss: 0.6866 - val_loss: 0.7302\n",
      "Epoch 102/100000\n",
      "9988/9988 [==============================] - 7s 654us/step - loss: 0.6846 - val_loss: 0.7042\n",
      "Epoch 103/100000\n",
      "9988/9988 [==============================] - 7s 675us/step - loss: 0.6842 - val_loss: 0.7155\n",
      "Epoch 104/100000\n",
      "9988/9988 [==============================] - 7s 672us/step - loss: 0.6832 - val_loss: 0.7226\n",
      "Epoch 105/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.6813 - val_loss: 0.7403\n",
      "Epoch 106/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.6794 - val_loss: 0.7117\n",
      "Epoch 107/100000\n",
      "9988/9988 [==============================] - 14s 1ms/step - loss: 0.6787 - val_loss: 0.7059\n",
      "Epoch 108/100000\n",
      "9988/9988 [==============================] - 13s 1ms/step - loss: 0.6770 - val_loss: 0.7252\n",
      "Epoch 109/100000\n",
      "9988/9988 [==============================] - 10s 979us/step - loss: 0.6770 - val_loss: 0.7348\n",
      "Epoch 110/100000\n",
      "9988/9988 [==============================] - 9s 852us/step - loss: 0.6755 - val_loss: 0.7193\n",
      "Epoch 111/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.6732 - val_loss: 0.7191\n",
      "Epoch 112/100000\n",
      "9988/9988 [==============================] - 12s 1ms/step - loss: 0.6722 - val_loss: 0.6984\n",
      "Epoch 113/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.6716 - val_loss: 0.7083\n",
      "Epoch 114/100000\n",
      "9988/9988 [==============================] - 8s 840us/step - loss: 0.6706 - val_loss: 0.7055\n",
      "Epoch 115/100000\n",
      "9988/9988 [==============================] - 13s 1ms/step - loss: 0.6684 - val_loss: 0.7278\n",
      "Epoch 116/100000\n",
      "9988/9988 [==============================] - 9s 918us/step - loss: 0.6679 - val_loss: 0.7086\n",
      "Epoch 117/100000\n",
      "9988/9988 [==============================] - 11s 1ms/step - loss: 0.6663 - val_loss: 0.6998\n",
      "Epoch 118/100000\n",
      "9988/9988 [==============================] - 8s 795us/step - loss: 0.6657 - val_loss: 0.7090\n",
      "Epoch 119/100000\n",
      "9988/9988 [==============================] - 8s 794us/step - loss: 0.6657 - val_loss: 0.7174\n",
      "Epoch 120/100000\n",
      "9988/9988 [==============================] - 7s 738us/step - loss: 0.6629 - val_loss: 0.6865\n",
      "Epoch 121/100000\n",
      "9988/9988 [==============================] - 6s 646us/step - loss: 0.6628 - val_loss: 0.6990\n",
      "Epoch 122/100000\n",
      "9988/9988 [==============================] - 6s 632us/step - loss: 0.6620 - val_loss: 0.6920\n",
      "Epoch 123/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.6614 - val_loss: 0.7007\n",
      "Epoch 124/100000\n",
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.6607 - val_loss: 0.7041\n",
      "Epoch 125/100000\n",
      "9988/9988 [==============================] - 6s 647us/step - loss: 0.6586 - val_loss: 0.6903\n",
      "Epoch 126/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.6580 - val_loss: 0.7115\n",
      "Epoch 127/100000\n",
      "9988/9988 [==============================] - 6s 630us/step - loss: 0.6576 - val_loss: 0.6920\n",
      "Epoch 128/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6551 - val_loss: 0.7113\n",
      "Epoch 129/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.6554 - val_loss: 0.7089\n",
      "Epoch 130/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.6552 - val_loss: 0.6855\n",
      "Epoch 131/100000\n",
      "9988/9988 [==============================] - 6s 629us/step - loss: 0.6529 - val_loss: 0.7009\n",
      "Epoch 132/100000\n",
      "9988/9988 [==============================] - 6s 629us/step - loss: 0.6524 - val_loss: 0.6947\n",
      "Epoch 133/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6524 - val_loss: 0.6893\n",
      "Epoch 134/100000\n",
      "9988/9988 [==============================] - 6s 640us/step - loss: 0.6506 - val_loss: 0.6901\n",
      "Epoch 135/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6496 - val_loss: 0.7029\n",
      "Epoch 136/100000\n",
      "9988/9988 [==============================] - 6s 628us/step - loss: 0.6502 - val_loss: 0.6964\n",
      "Epoch 137/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.6485 - val_loss: 0.6772\n",
      "Epoch 138/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.6484 - val_loss: 0.6821\n",
      "Epoch 139/100000\n",
      "9988/9988 [==============================] - 6s 635us/step - loss: 0.6470 - val_loss: 0.6946\n",
      "Epoch 140/100000\n",
      "9988/9988 [==============================] - 6s 630us/step - loss: 0.6470 - val_loss: 0.6949\n",
      "Epoch 141/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6465 - val_loss: 0.6907\n",
      "Epoch 142/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6455 - val_loss: 0.7087\n",
      "Epoch 143/100000\n",
      "9988/9988 [==============================] - 6s 628us/step - loss: 0.6446 - val_loss: 0.6841\n",
      "Epoch 144/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.6433 - val_loss: 0.6926\n",
      "Epoch 145/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.6438 - val_loss: 0.6766\n",
      "Epoch 146/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.6413 - val_loss: 0.6836\n",
      "Epoch 147/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.6415 - val_loss: 0.7153\n",
      "Epoch 148/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6408 - val_loss: 0.6984\n",
      "Epoch 149/100000\n",
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.6392 - val_loss: 0.6876\n",
      "Epoch 150/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6396 - val_loss: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.6389 - val_loss: 0.6772\n",
      "Epoch 152/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6381 - val_loss: 0.6901\n",
      "Epoch 153/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.6386 - val_loss: 0.7034\n",
      "Epoch 154/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.6366 - val_loss: 0.6938\n",
      "Epoch 155/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.6370 - val_loss: 0.6877\n",
      "Epoch 156/100000\n",
      "9988/9988 [==============================] - 6s 634us/step - loss: 0.6358 - val_loss: 0.6855\n",
      "Epoch 157/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6359 - val_loss: 0.6705\n",
      "Epoch 158/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.6340 - val_loss: 0.6862\n",
      "Epoch 159/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.6346 - val_loss: 0.6782\n",
      "Epoch 160/100000\n",
      "9988/9988 [==============================] - 6s 610us/step - loss: 0.6330 - val_loss: 0.6894\n",
      "Epoch 161/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.6333 - val_loss: 0.6793\n",
      "Epoch 162/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6318 - val_loss: 0.6664\n",
      "Epoch 163/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6310 - val_loss: 0.6819\n",
      "Epoch 164/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6324 - val_loss: 0.6859\n",
      "Epoch 165/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.6314 - val_loss: 0.6716\n",
      "Epoch 166/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6299 - val_loss: 0.6886\n",
      "Epoch 167/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.6302 - val_loss: 0.6771\n",
      "Epoch 168/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6290 - val_loss: 0.6779\n",
      "Epoch 169/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6303 - val_loss: 0.6784\n",
      "Epoch 170/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6292 - val_loss: 0.6828\n",
      "Epoch 171/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6285 - val_loss: 0.6882\n",
      "Epoch 172/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6281 - val_loss: 0.6671\n",
      "Epoch 173/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6269 - val_loss: 0.6652\n",
      "Epoch 174/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6260 - val_loss: 0.6740\n",
      "Epoch 175/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.6265 - val_loss: 0.6666\n",
      "Epoch 176/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6253 - val_loss: 0.6906\n",
      "Epoch 177/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.6252 - val_loss: 0.6875\n",
      "Epoch 178/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.6256 - val_loss: 0.6861\n",
      "Epoch 179/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6246 - val_loss: 0.6781\n",
      "Epoch 180/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6243 - val_loss: 0.6800\n",
      "Epoch 181/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6227 - val_loss: 0.6670\n",
      "Epoch 182/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6233 - val_loss: 0.6766\n",
      "Epoch 183/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.6214 - val_loss: 0.6763\n",
      "Epoch 184/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6226 - val_loss: 0.6716\n",
      "Epoch 185/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.6219 - val_loss: 0.6720\n",
      "Epoch 186/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6209 - val_loss: 0.6651\n",
      "Epoch 187/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6204 - val_loss: 0.6686\n",
      "Epoch 188/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6215 - val_loss: 0.6714\n",
      "Epoch 189/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6191 - val_loss: 0.6687\n",
      "Epoch 190/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6199 - val_loss: 0.6741\n",
      "Epoch 191/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6189 - val_loss: 0.6668\n",
      "Epoch 192/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6188 - val_loss: 0.6630\n",
      "Epoch 193/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6176 - val_loss: 0.6793\n",
      "Epoch 194/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.6186 - val_loss: 0.6706\n",
      "Epoch 195/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6171 - val_loss: 0.6711\n",
      "Epoch 196/100000\n",
      "9988/9988 [==============================] - 6s 639us/step - loss: 0.6155 - val_loss: 0.6641\n",
      "Epoch 197/100000\n",
      "9988/9988 [==============================] - 6s 639us/step - loss: 0.6166 - val_loss: 0.6673\n",
      "Epoch 198/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6167 - val_loss: 0.6895\n",
      "Epoch 199/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6159 - val_loss: 0.6666\n",
      "Epoch 200/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6138 - val_loss: 0.6672\n",
      "Epoch 201/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6142 - val_loss: 0.6727\n",
      "Epoch 202/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6132 - val_loss: 0.6597\n",
      "Epoch 203/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6142 - val_loss: 0.6784\n",
      "Epoch 204/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.6131 - val_loss: 0.6623\n",
      "Epoch 205/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.6140 - val_loss: 0.6651\n",
      "Epoch 206/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6129 - val_loss: 0.6727\n",
      "Epoch 207/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6116 - val_loss: 0.6632\n",
      "Epoch 208/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6100 - val_loss: 0.6774\n",
      "Epoch 209/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6102 - val_loss: 0.6640\n",
      "Epoch 210/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6099 - val_loss: 0.6693\n",
      "Epoch 211/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6103 - val_loss: 0.6639\n",
      "Epoch 212/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6091 - val_loss: 0.6752\n",
      "Epoch 213/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6093 - val_loss: 0.6612\n",
      "Epoch 214/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6096 - val_loss: 0.6855\n",
      "Epoch 215/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.6088 - val_loss: 0.6596\n",
      "Epoch 216/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.6079 - val_loss: 0.6569\n",
      "Epoch 217/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6085 - val_loss: 0.6631\n",
      "Epoch 218/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6084 - val_loss: 0.6646\n",
      "Epoch 219/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6085 - val_loss: 0.6809\n",
      "Epoch 220/100000\n",
      "9988/9988 [==============================] - 7s 659us/step - loss: 0.6062 - val_loss: 0.6643\n",
      "Epoch 221/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6071 - val_loss: 0.6662\n",
      "Epoch 222/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.6066 - val_loss: 0.6741\n",
      "Epoch 223/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.6066 - val_loss: 0.6569\n",
      "Epoch 224/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6055 - val_loss: 0.6627\n",
      "Epoch 225/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6064 - val_loss: 0.6664\n",
      "Epoch 226/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6057 - val_loss: 0.6658\n",
      "Epoch 227/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.6055 - val_loss: 0.6688\n",
      "Epoch 228/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6056 - val_loss: 0.6756\n",
      "Epoch 229/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6053 - val_loss: 0.6619\n",
      "Epoch 230/100000\n",
      "9988/9988 [==============================] - 6s 612us/step - loss: 0.6042 - val_loss: 0.6623\n",
      "Epoch 231/100000\n",
      "9988/9988 [==============================] - 6s 631us/step - loss: 0.6042 - val_loss: 0.6659\n",
      "Epoch 232/100000\n",
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.6052 - val_loss: 0.6686\n",
      "Epoch 233/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6037 - val_loss: 0.6593\n",
      "Epoch 234/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.6046 - val_loss: 0.6686\n",
      "Epoch 235/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6038 - val_loss: 0.6600\n",
      "Epoch 236/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.6034 - val_loss: 0.6667\n",
      "Epoch 237/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6035 - val_loss: 0.6649\n",
      "Epoch 238/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6034 - val_loss: 0.6612\n",
      "Epoch 239/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6025 - val_loss: 0.6648\n",
      "Epoch 240/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6019 - val_loss: 0.6743\n",
      "Epoch 241/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.6024 - val_loss: 0.6860\n",
      "Epoch 242/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.6016 - val_loss: 0.6720\n",
      "Epoch 243/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6000 - val_loss: 0.6624\n",
      "Epoch 244/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.6001 - val_loss: 0.6573\n",
      "Epoch 245/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.6005 - val_loss: 0.6658\n",
      "Epoch 246/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.6005 - val_loss: 0.6743\n",
      "Epoch 247/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.6013 - val_loss: 0.6668\n",
      "Epoch 248/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.6001 - val_loss: 0.6655\n",
      "Epoch 249/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5994 - val_loss: 0.6635\n",
      "Epoch 250/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5989 - val_loss: 0.6576\n",
      "Epoch 251/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5985 - val_loss: 0.6566\n",
      "Epoch 252/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5984 - val_loss: 0.6712\n",
      "Epoch 253/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5974 - val_loss: 0.6580\n",
      "Epoch 254/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5980 - val_loss: 0.6569\n",
      "Epoch 255/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.5959 - val_loss: 0.6710\n",
      "Epoch 256/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5963 - val_loss: 0.6645\n",
      "Epoch 257/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5960 - val_loss: 0.6575\n",
      "Epoch 258/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5963 - val_loss: 0.6754\n",
      "Epoch 259/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5959 - val_loss: 0.6596\n",
      "Epoch 260/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5963 - val_loss: 0.6625\n",
      "Epoch 261/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5957 - val_loss: 0.6713\n",
      "Epoch 262/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5958 - val_loss: 0.6649\n",
      "Epoch 263/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5956 - val_loss: 0.6524\n",
      "Epoch 264/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5937 - val_loss: 0.6709\n",
      "Epoch 265/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5939 - val_loss: 0.6546\n",
      "Epoch 266/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5939 - val_loss: 0.6532\n",
      "Epoch 267/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5946 - val_loss: 0.6591\n",
      "Epoch 268/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5941 - val_loss: 0.6715\n",
      "Epoch 269/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5945 - val_loss: 0.6603\n",
      "Epoch 270/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5932 - val_loss: 0.6656\n",
      "Epoch 271/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5932 - val_loss: 0.6664\n",
      "Epoch 272/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5938 - val_loss: 0.6609\n",
      "Epoch 273/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5934 - val_loss: 0.6567\n",
      "Epoch 274/100000\n",
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.5933 - val_loss: 0.6584\n",
      "Epoch 275/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5923 - val_loss: 0.6554\n",
      "Epoch 276/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5920 - val_loss: 0.6587\n",
      "Epoch 277/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5932 - val_loss: 0.6702\n",
      "Epoch 278/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5928 - val_loss: 0.6689\n",
      "Epoch 279/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5923 - val_loss: 0.6591\n",
      "Epoch 280/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5913 - val_loss: 0.6664\n",
      "Epoch 281/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5909 - val_loss: 0.6658\n",
      "Epoch 282/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5908 - val_loss: 0.6608\n",
      "Epoch 283/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5903 - val_loss: 0.6570\n",
      "Epoch 284/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5908 - val_loss: 0.6591\n",
      "Epoch 285/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5900 - val_loss: 0.6492\n",
      "Epoch 286/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5903 - val_loss: 0.6630\n",
      "Epoch 287/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5903 - val_loss: 0.6492\n",
      "Epoch 288/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5902 - val_loss: 0.6574\n",
      "Epoch 289/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5903 - val_loss: 0.6530\n",
      "Epoch 290/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5898 - val_loss: 0.6596\n",
      "Epoch 291/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5897 - val_loss: 0.6608\n",
      "Epoch 292/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5892 - val_loss: 0.6573\n",
      "Epoch 293/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5891 - val_loss: 0.6611\n",
      "Epoch 294/100000\n",
      "9988/9988 [==============================] - 6s 628us/step - loss: 0.5894 - val_loss: 0.6598\n",
      "Epoch 295/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.5880 - val_loss: 0.6514\n",
      "Epoch 296/100000\n",
      "9988/9988 [==============================] - 6s 632us/step - loss: 0.5884 - val_loss: 0.6616\n",
      "Epoch 297/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5884 - val_loss: 0.6528\n",
      "Epoch 298/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5883 - val_loss: 0.6547\n",
      "Epoch 299/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5883 - val_loss: 0.6656\n",
      "Epoch 300/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5885 - val_loss: 0.6585\n",
      "Epoch 301/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5879 - val_loss: 0.6742\n",
      "Epoch 302/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5867 - val_loss: 0.6546\n",
      "Epoch 303/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5858 - val_loss: 0.6556\n",
      "Epoch 304/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5855 - val_loss: 0.6485\n",
      "Epoch 305/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5859 - val_loss: 0.6581\n",
      "Epoch 306/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5867 - val_loss: 0.6594\n",
      "Epoch 307/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5860 - val_loss: 0.6634\n",
      "Epoch 308/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5854 - val_loss: 0.6604\n",
      "Epoch 309/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5862 - val_loss: 0.6524\n",
      "Epoch 310/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5853 - val_loss: 0.6678\n",
      "Epoch 311/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5848 - val_loss: 0.6607\n",
      "Epoch 312/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5854 - val_loss: 0.6557\n",
      "Epoch 313/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5849 - val_loss: 0.6597\n",
      "Epoch 314/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5849 - val_loss: 0.6590\n",
      "Epoch 315/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5843 - val_loss: 0.6617\n",
      "Epoch 316/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5847 - val_loss: 0.6610\n",
      "Epoch 317/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5841 - val_loss: 0.6609\n",
      "Epoch 318/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5841 - val_loss: 0.6656\n",
      "Epoch 319/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5838 - val_loss: 0.6509\n",
      "Epoch 320/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5836 - val_loss: 0.6538\n",
      "Epoch 321/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5841 - val_loss: 0.6607\n",
      "Epoch 322/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5832 - val_loss: 0.6569\n",
      "Epoch 323/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5833 - val_loss: 0.6693\n",
      "Epoch 324/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5824 - val_loss: 0.6661\n",
      "Epoch 325/100000\n",
      "9988/9988 [==============================] - 6s 612us/step - loss: 0.5821 - val_loss: 0.6541\n",
      "Epoch 326/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5824 - val_loss: 0.6493\n",
      "Epoch 327/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5834 - val_loss: 0.6532\n",
      "Epoch 328/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5823 - val_loss: 0.6575\n",
      "Epoch 329/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5824 - val_loss: 0.6616\n",
      "Epoch 330/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5817 - val_loss: 0.6574\n",
      "Epoch 331/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5818 - val_loss: 0.6502\n",
      "Epoch 332/100000\n",
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.5824 - val_loss: 0.6662\n",
      "Epoch 333/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5814 - val_loss: 0.6586\n",
      "Epoch 334/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5814 - val_loss: 0.6522\n",
      "Epoch 335/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5817 - val_loss: 0.6485\n",
      "Epoch 336/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5811 - val_loss: 0.6578\n",
      "Epoch 337/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5823 - val_loss: 0.6532\n",
      "Epoch 338/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5815 - val_loss: 0.6550\n",
      "Epoch 339/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5798 - val_loss: 0.6716\n",
      "Epoch 340/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5797 - val_loss: 0.6578\n",
      "Epoch 341/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5801 - val_loss: 0.6544\n",
      "Epoch 342/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5800 - val_loss: 0.6517\n",
      "Epoch 343/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5802 - val_loss: 0.6541\n",
      "Epoch 344/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5804 - val_loss: 0.6538\n",
      "Epoch 345/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5796 - val_loss: 0.6582\n",
      "Epoch 346/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5794 - val_loss: 0.6585\n",
      "Epoch 347/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5790 - val_loss: 0.6513\n",
      "Epoch 348/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5798 - val_loss: 0.6728\n",
      "Epoch 349/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5786 - val_loss: 0.6516\n",
      "Epoch 350/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5791 - val_loss: 0.6665\n",
      "Epoch 351/100000\n",
      "9988/9988 [==============================] - 6s 628us/step - loss: 0.5794 - val_loss: 0.6496\n",
      "Epoch 352/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5788 - val_loss: 0.6525\n",
      "Epoch 353/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5788 - val_loss: 0.6546\n",
      "Epoch 354/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5790 - val_loss: 0.6600\n",
      "Epoch 355/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5782 - val_loss: 0.6603\n",
      "Epoch 356/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5778 - val_loss: 0.6529\n",
      "Epoch 357/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5784 - val_loss: 0.6571\n",
      "Epoch 358/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5771 - val_loss: 0.6615\n",
      "Epoch 359/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5767 - val_loss: 0.6582\n",
      "Epoch 360/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5774 - val_loss: 0.6536\n",
      "Epoch 361/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5774 - val_loss: 0.6631\n",
      "Epoch 362/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5771 - val_loss: 0.6569\n",
      "Epoch 363/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5764 - val_loss: 0.6576\n",
      "Epoch 364/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5762 - val_loss: 0.6446\n",
      "Epoch 365/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5766 - val_loss: 0.6578\n",
      "Epoch 366/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5770 - val_loss: 0.6548\n",
      "Epoch 367/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5763 - val_loss: 0.6454\n",
      "Epoch 368/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5765 - val_loss: 0.6543\n",
      "Epoch 369/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5761 - val_loss: 0.6519\n",
      "Epoch 370/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5763 - val_loss: 0.6613\n",
      "Epoch 371/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5764 - val_loss: 0.6522\n",
      "Epoch 372/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5757 - val_loss: 0.6560\n",
      "Epoch 373/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5751 - val_loss: 0.6564\n",
      "Epoch 374/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5754 - val_loss: 0.6495\n",
      "Epoch 375/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5751 - val_loss: 0.6572\n",
      "Epoch 376/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5746 - val_loss: 0.6492\n",
      "Epoch 377/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5755 - val_loss: 0.6508\n",
      "Epoch 378/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5750 - val_loss: 0.6594\n",
      "Epoch 379/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.5752 - val_loss: 0.6488\n",
      "Epoch 380/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5747 - val_loss: 0.6510\n",
      "Epoch 381/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5737 - val_loss: 0.6604\n",
      "Epoch 382/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5739 - val_loss: 0.6423\n",
      "Epoch 383/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5731 - val_loss: 0.6514\n",
      "Epoch 384/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5736 - val_loss: 0.6526\n",
      "Epoch 385/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5736 - val_loss: 0.6558\n",
      "Epoch 386/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5733 - val_loss: 0.6555\n",
      "Epoch 387/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5725 - val_loss: 0.6549\n",
      "Epoch 388/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5732 - val_loss: 0.6456\n",
      "Epoch 389/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5740 - val_loss: 0.6596\n",
      "Epoch 390/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5729 - val_loss: 0.6741\n",
      "Epoch 391/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.5730 - val_loss: 0.6521\n",
      "Epoch 392/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5729 - val_loss: 0.6589\n",
      "Epoch 393/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5716 - val_loss: 0.6521\n",
      "Epoch 394/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5720 - val_loss: 0.6551\n",
      "Epoch 395/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5714 - val_loss: 0.6572\n",
      "Epoch 396/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5725 - val_loss: 0.6662\n",
      "Epoch 397/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5710 - val_loss: 0.6567\n",
      "Epoch 398/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5716 - val_loss: 0.6464\n",
      "Epoch 399/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5712 - val_loss: 0.6526\n",
      "Epoch 400/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5716 - val_loss: 0.6606\n",
      "Epoch 401/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5717 - val_loss: 0.6534\n",
      "Epoch 402/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5719 - val_loss: 0.6543\n",
      "Epoch 403/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5719 - val_loss: 0.6555\n",
      "Epoch 404/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5716 - val_loss: 0.6655\n",
      "Epoch 405/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5725 - val_loss: 0.6470\n",
      "Epoch 406/100000\n",
      "9988/9988 [==============================] - 6s 612us/step - loss: 0.5711 - val_loss: 0.6609\n",
      "Epoch 407/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5711 - val_loss: 0.6505\n",
      "Epoch 408/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5705 - val_loss: 0.6483\n",
      "Epoch 409/100000\n",
      "9988/9988 [==============================] - 6s 625us/step - loss: 0.5704 - val_loss: 0.6613\n",
      "Epoch 410/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5700 - val_loss: 0.6495\n",
      "Epoch 411/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5691 - val_loss: 0.6516\n",
      "Epoch 412/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5702 - val_loss: 0.6499\n",
      "Epoch 413/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5706 - val_loss: 0.6513\n",
      "Epoch 414/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5694 - val_loss: 0.6529\n",
      "Epoch 415/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5703 - val_loss: 0.6473\n",
      "Epoch 416/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5704 - val_loss: 0.6473\n",
      "Epoch 417/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5692 - val_loss: 0.6529\n",
      "Epoch 418/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5691 - val_loss: 0.6582\n",
      "Epoch 419/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5700 - val_loss: 0.6546\n",
      "Epoch 420/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5692 - val_loss: 0.6478\n",
      "Epoch 421/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5693 - val_loss: 0.6567\n",
      "Epoch 422/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5697 - val_loss: 0.6578\n",
      "Epoch 423/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5685 - val_loss: 0.6555\n",
      "Epoch 424/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5687 - val_loss: 0.6617\n",
      "Epoch 425/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5688 - val_loss: 0.6535\n",
      "Epoch 426/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5681 - val_loss: 0.6613\n",
      "Epoch 427/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5681 - val_loss: 0.6546\n",
      "Epoch 428/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5677 - val_loss: 0.6510\n",
      "Epoch 429/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5686 - val_loss: 0.6529\n",
      "Epoch 430/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5682 - val_loss: 0.6471\n",
      "Epoch 431/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5678 - val_loss: 0.6598\n",
      "Epoch 432/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5677 - val_loss: 0.6508\n",
      "Epoch 433/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5672 - val_loss: 0.6555\n",
      "Epoch 434/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5671 - val_loss: 0.6543\n",
      "Epoch 435/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5672 - val_loss: 0.6496\n",
      "Epoch 436/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5668 - val_loss: 0.6522\n",
      "Epoch 437/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5668 - val_loss: 0.6495\n",
      "Epoch 438/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5663 - val_loss: 0.6566\n",
      "Epoch 439/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5680 - val_loss: 0.6564\n",
      "Epoch 440/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5666 - val_loss: 0.6543\n",
      "Epoch 441/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5671 - val_loss: 0.6572\n",
      "Epoch 442/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5672 - val_loss: 0.6503\n",
      "Epoch 443/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5673 - val_loss: 0.6605\n",
      "Epoch 444/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5667 - val_loss: 0.6534\n",
      "Epoch 445/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5667 - val_loss: 0.6553\n",
      "Epoch 446/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5661 - val_loss: 0.6516\n",
      "Epoch 447/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.5659 - val_loss: 0.6465\n",
      "Epoch 448/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5663 - val_loss: 0.6480\n",
      "Epoch 449/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5667 - val_loss: 0.6564\n",
      "Epoch 450/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5655 - val_loss: 0.6534\n",
      "Epoch 451/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5658 - val_loss: 0.6530\n",
      "Epoch 452/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5649 - val_loss: 0.6549\n",
      "Epoch 453/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5661 - val_loss: 0.6498\n",
      "Epoch 454/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5665 - val_loss: 0.6538\n",
      "Epoch 455/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5651 - val_loss: 0.6565\n",
      "Epoch 456/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5655 - val_loss: 0.6492\n",
      "Epoch 457/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5657 - val_loss: 0.6448\n",
      "Epoch 458/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5658 - val_loss: 0.6629\n",
      "Epoch 459/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5649 - val_loss: 0.6591\n",
      "Epoch 460/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.5654 - val_loss: 0.6619\n",
      "Epoch 461/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5650 - val_loss: 0.6528\n",
      "Epoch 462/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5641 - val_loss: 0.6696\n",
      "Epoch 463/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5650 - val_loss: 0.6647\n",
      "Epoch 464/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5637 - val_loss: 0.6582\n",
      "Epoch 465/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5642 - val_loss: 0.6511\n",
      "Epoch 466/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5646 - val_loss: 0.6527\n",
      "Epoch 467/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5647 - val_loss: 0.6523\n",
      "Epoch 468/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5651 - val_loss: 0.6486\n",
      "Epoch 469/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5650 - val_loss: 0.6513\n",
      "Epoch 470/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5656 - val_loss: 0.6570\n",
      "Epoch 471/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5635 - val_loss: 0.6538\n",
      "Epoch 472/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5648 - val_loss: 0.6478\n",
      "Epoch 473/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5638 - val_loss: 0.6650\n",
      "Epoch 474/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5633 - val_loss: 0.6503\n",
      "Epoch 475/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5634 - val_loss: 0.6515\n",
      "Epoch 476/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5636 - val_loss: 0.6583\n",
      "Epoch 477/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5633 - val_loss: 0.6587\n",
      "Epoch 478/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5638 - val_loss: 0.6419\n",
      "Epoch 479/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5636 - val_loss: 0.6530\n",
      "Epoch 480/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5641 - val_loss: 0.6501\n",
      "Epoch 481/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5634 - val_loss: 0.6497\n",
      "Epoch 482/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5625 - val_loss: 0.6491\n",
      "Epoch 483/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5636 - val_loss: 0.6491\n",
      "Epoch 484/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5635 - val_loss: 0.6583\n",
      "Epoch 485/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5634 - val_loss: 0.6541\n",
      "Epoch 486/100000\n",
      "9988/9988 [==============================] - 6s 626us/step - loss: 0.5639 - val_loss: 0.6541\n",
      "Epoch 487/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5621 - val_loss: 0.6509\n",
      "Epoch 488/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5628 - val_loss: 0.6575\n",
      "Epoch 489/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5628 - val_loss: 0.6506\n",
      "Epoch 490/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5612 - val_loss: 0.6488\n",
      "Epoch 491/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5623 - val_loss: 0.6523\n",
      "Epoch 492/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5616 - val_loss: 0.6595\n",
      "Epoch 493/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5624 - val_loss: 0.6582\n",
      "Epoch 494/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5619 - val_loss: 0.6515\n",
      "Epoch 495/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5613 - val_loss: 0.6498\n",
      "Epoch 496/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5609 - val_loss: 0.6562\n",
      "Epoch 497/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5620 - val_loss: 0.6578\n",
      "Epoch 498/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5619 - val_loss: 0.6489\n",
      "Epoch 499/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5613 - val_loss: 0.6481\n",
      "Epoch 500/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5614 - val_loss: 0.6451\n",
      "Epoch 501/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5616 - val_loss: 0.6538\n",
      "Epoch 502/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5610 - val_loss: 0.6546\n",
      "Epoch 503/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5612 - val_loss: 0.6505\n",
      "Epoch 504/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5610 - val_loss: 0.6464\n",
      "Epoch 505/100000\n",
      "9988/9988 [==============================] - 6s 624us/step - loss: 0.5601 - val_loss: 0.6540\n",
      "Epoch 506/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5603 - val_loss: 0.6500\n",
      "Epoch 507/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5601 - val_loss: 0.6543\n",
      "Epoch 508/100000\n",
      "9988/9988 [==============================] - 6s 650us/step - loss: 0.5604 - val_loss: 0.6567\n",
      "Epoch 509/100000\n",
      "9988/9988 [==============================] - 6s 629us/step - loss: 0.5603 - val_loss: 0.6487\n",
      "Epoch 510/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5604 - val_loss: 0.6494\n",
      "Epoch 511/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5609 - val_loss: 0.6539\n",
      "Epoch 512/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5601 - val_loss: 0.6462\n",
      "Epoch 513/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5597 - val_loss: 0.6479\n",
      "Epoch 514/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5595 - val_loss: 0.6511\n",
      "Epoch 515/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5610 - val_loss: 0.6590\n",
      "Epoch 516/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5600 - val_loss: 0.6562\n",
      "Epoch 517/100000\n",
      "9988/9988 [==============================] - 6s 642us/step - loss: 0.5596 - val_loss: 0.6603\n",
      "Epoch 518/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5593 - val_loss: 0.6535\n",
      "Epoch 519/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5594 - val_loss: 0.6634\n",
      "Epoch 520/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5593 - val_loss: 0.6496\n",
      "Epoch 521/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5606 - val_loss: 0.6587\n",
      "Epoch 522/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5596 - val_loss: 0.6445\n",
      "Epoch 523/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5597 - val_loss: 0.6613\n",
      "Epoch 524/100000\n",
      "9988/9988 [==============================] - 6s 621us/step - loss: 0.5603 - val_loss: 0.6521\n",
      "Epoch 525/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5594 - val_loss: 0.6667\n",
      "Epoch 526/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5594 - val_loss: 0.6557\n",
      "Epoch 527/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5596 - val_loss: 0.6494\n",
      "Epoch 528/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5591 - val_loss: 0.6572\n",
      "Epoch 529/100000\n",
      "9988/9988 [==============================] - 6s 614us/step - loss: 0.5594 - val_loss: 0.6516\n",
      "Epoch 530/100000\n",
      "9988/9988 [==============================] - 6s 613us/step - loss: 0.5593 - val_loss: 0.6591\n",
      "Epoch 531/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5593 - val_loss: 0.6566\n",
      "Epoch 532/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5591 - val_loss: 0.6483\n",
      "Epoch 533/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5594 - val_loss: 0.6467\n",
      "Epoch 534/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5590 - val_loss: 0.6496\n",
      "Epoch 535/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5588 - val_loss: 0.6557\n",
      "Epoch 536/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5595 - val_loss: 0.6542\n",
      "Epoch 537/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5592 - val_loss: 0.6617\n",
      "Epoch 538/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5584 - val_loss: 0.6572\n",
      "Epoch 539/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5586 - val_loss: 0.6571\n",
      "Epoch 540/100000\n",
      "9988/9988 [==============================] - 6s 634us/step - loss: 0.5592 - val_loss: 0.6585\n",
      "Epoch 541/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5584 - val_loss: 0.6540\n",
      "Epoch 542/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5596 - val_loss: 0.6584\n",
      "Epoch 543/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5583 - val_loss: 0.6531\n",
      "Epoch 544/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.5583 - val_loss: 0.6465\n",
      "Epoch 545/100000\n",
      "9988/9988 [==============================] - 6s 615us/step - loss: 0.5591 - val_loss: 0.6557\n",
      "Epoch 546/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5570 - val_loss: 0.6490\n",
      "Epoch 547/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5575 - val_loss: 0.6561\n",
      "Epoch 548/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5582 - val_loss: 0.6549\n",
      "Epoch 549/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5581 - val_loss: 0.6505\n",
      "Epoch 550/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5570 - val_loss: 0.6521\n",
      "Epoch 551/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5573 - val_loss: 0.6577\n",
      "Epoch 552/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5572 - val_loss: 0.6509\n",
      "Epoch 553/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5570 - val_loss: 0.6594\n",
      "Epoch 554/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5574 - val_loss: 0.6502\n",
      "Epoch 555/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5567 - val_loss: 0.6561\n",
      "Epoch 556/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5572 - val_loss: 0.6498\n",
      "Epoch 557/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5565 - val_loss: 0.6454\n",
      "Epoch 558/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5567 - val_loss: 0.6464\n",
      "Epoch 559/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5570 - val_loss: 0.6524\n",
      "Epoch 560/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5566 - val_loss: 0.6568\n",
      "Epoch 561/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5562 - val_loss: 0.6530\n",
      "Epoch 562/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5561 - val_loss: 0.6601\n",
      "Epoch 563/100000\n",
      "9988/9988 [==============================] - 6s 627us/step - loss: 0.5566 - val_loss: 0.6559\n",
      "Epoch 564/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5556 - val_loss: 0.6514\n",
      "Epoch 565/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5561 - val_loss: 0.6581\n",
      "Epoch 566/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5564 - val_loss: 0.6548\n",
      "Epoch 567/100000\n",
      "9988/9988 [==============================] - 6s 622us/step - loss: 0.5562 - val_loss: 0.6554\n",
      "Epoch 568/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5550 - val_loss: 0.6523\n",
      "Epoch 569/100000\n",
      "9988/9988 [==============================] - 6s 620us/step - loss: 0.5555 - val_loss: 0.6598\n",
      "Epoch 570/100000\n",
      "9988/9988 [==============================] - 6s 617us/step - loss: 0.5570 - val_loss: 0.6558\n",
      "Epoch 571/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5557 - val_loss: 0.6609\n",
      "Epoch 572/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5554 - val_loss: 0.6472\n",
      "Epoch 573/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5557 - val_loss: 0.6501\n",
      "Epoch 574/100000\n",
      "9988/9988 [==============================] - 6s 623us/step - loss: 0.5559 - val_loss: 0.6542\n",
      "Epoch 575/100000\n",
      "9988/9988 [==============================] - 6s 616us/step - loss: 0.5556 - val_loss: 0.6551\n",
      "Epoch 576/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5554 - val_loss: 0.6569\n",
      "Epoch 577/100000\n",
      "9988/9988 [==============================] - 6s 618us/step - loss: 0.5550 - val_loss: 0.6524\n",
      "Epoch 578/100000\n",
      "9988/9988 [==============================] - 6s 619us/step - loss: 0.5556 - val_loss: 0.6592\n",
      "Epoch 00578: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run autoencoder\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Euclidean distance loss\n",
    "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# Stop if there has been no improvement for 100 epochs\n",
    "es = keras.callbacks.EarlyStopping(verbose=1, patience=100)\n",
    "# Save best model while training\n",
    "mc = keras.callbacks.ModelCheckpoint('model/best_model.h5')\n",
    "\n",
    "callbacks_list = [es, mc]\n",
    "\n",
    "m = Sequential()\n",
    "\n",
    "m.add(Dense(512, activation='elu', input_shape=(features_train_scaled.shape[1],)))\n",
    "m.add(Dense(32, activation='linear', name=\"bottleneck\"))\n",
    "m.add(Dense(512, activation='elu'))\n",
    "m.add(Dense(features_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "m.compile(loss=euclidean_distance_loss, optimizer=Adadelta())\n",
    "\n",
    "history = m.fit(features_train_scaled, features_train_scaled, batch_size=128, epochs=100000, verbose=1,\n",
    "                validation_data=(features_test_scaled, features_test_scaled), callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model('model/best_model.h5', custom_objects={'euclidean_distance_loss': euclidean_distance_loss})\n",
    "encoder = Model(best_model.input, best_model.get_layer('bottleneck').output)\n",
    "encoder.save('model/encoder.h5')\n",
    "enc = encoder.predict(features_train_scaled) # returns the encoded values (32 floats instead of 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=100)\n",
    "\n",
    "result = neigh.fit(features_train_scaled)\n",
    "neighbours = result.kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_enc = neigh.fit(enc)\n",
    "neighbours_enc = result_enc.kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_r = best_model.predict(features_train_scaled)      # reconstruction, 2048 -> 32 -> 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_enc_r = neigh.fit(enc_r)\n",
    "neighbours_enc_r = result_enc.kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(features_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394322"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(features_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7660 1670 9953 2328 4754 5231 3933 3615 5016 8144  845 3968 2536 3195\n",
      " 6196 4097  718 7788 5408 2647  518 5040 4864 4575 1770 9056 8033 7478\n",
      " 4951 2166 4191 6421  517 1543 8813 5359 4277 8095 7013 3690 5636 7361\n",
      " 8172 7560 6996 5918 9501 7606 3529 2585  250 8639  862 3559 8492 4168\n",
      " 4758 4274 4066 5039 6448 3983 4761 6428 1007 5149 3798 5564 3012 1772\n",
      " 1371 8543 1615 4985 2898 6852 6004 9280 7551 2933 3672 1213 9048 2102\n",
      " 8416 1662 8217 7310 8392 8613 5421 9878 6746 8466 7471 2660 6458 1422\n",
      " 9876 4102]\n",
      "[7660 1670 5231 9953 3615 2328 4754 8144 2536 3195 3968 5016 3933 4097\n",
      "  718 7788 4191  845 4575 7478 5040 5408 6421 1770 6196  250 1543 2647\n",
      " 5636  518 3690 9056 4864 4951 5359 5918  862 3559 2166 2585 7361 8172\n",
      " 3983 4758 6996 8033 7551  517 8813 4274 7013 9501 5564 6448 4066 5149\n",
      " 4277 3529 1007 7606 8095 4761 7560 1371 1772 7471 8639 3012 9185 8492\n",
      " 4985 1662 1213 5039 4168 8854 2119  655 4102 6470 2898 3798 9280 8613\n",
      " 2933 6126 6428 9048 1615 4818 3353 8416 7649 3054  343 8217 8392 9876\n",
      " 2660 7284]\n",
      "[7660 1670 2536 3615 5231 9953 4754 4097  845 8144 2328 3195 7788 3933\n",
      " 3968 5408 5016 4575  718 1770 4191  250  518 9056 1543 5040 7478 2647\n",
      " 6421 5636 7013 4864 6196 4951 8172 4761 6996 4758 3690 5359 8033 3983\n",
      "  517 2585 9501 3559 8095 5918 1213 7560 8813 4277 7361 6448 2166  862\n",
      " 8217 8639 2119 3012 8492 3529 8543 7606 5564 4168 1007 6470 8613 3798\n",
      " 9185 5149 4066  655 4274 1772 4818 7471 1662 7551 8416 4102 4985 6595\n",
      " 5440 6394 6428 3824  858 2660 8854 3353 9048 3131 2898 5923 3054 5421\n",
      " 1371 6458]\n"
     ]
    }
   ],
   "source": [
    "print(neighbours[1][0])\n",
    "print(neighbours_enc_r[1][0])\n",
    "print(neighbours_enc[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7369 1220 8549 3518 4840 9905 1127 2431 1836 7472 3556 4381 4379 2859\n",
      " 1296 6360 5743 9095 7863  916 7390 3367 7537 9562 2938 1884 8232 3897\n",
      " 2253 9584 2817  818 5492 2683 7422 3298 2755 3946 1169 9195 2978 1903\n",
      "  600 3353 3138 2710 9291 1420 3478 3786 3760 6420 2625 4990 4449 3039\n",
      " 8558 5125 8759 6910  463 1154  692 5917 1634 2943 6421 9433 7685 5114\n",
      " 4521 8808 3590 3040 2171  417 1864 7218 5497 9812 1994 7189 1515 9888\n",
      " 7706 1499 4846 3637 8560 8102 2428 2774 3233 2195 4960 8126 1874 7505\n",
      " 8090 1233]\n",
      "[1220 7369 9562 2431 3518 4379 4840 1836 5492 7246 6360 2253 8141 7252\n",
      " 8549  916 3556 1127 1169 9905 2978 1296 2710 9195 9799 7471 8232 2859\n",
      " 4381 2943 7472 3897 9095 8090 3353 3298 5114 7390  600 2938 7863 1233\n",
      " 8558 3138 3039  847 9584 3946 9888 3760 4990 6757 5743 4960 8126 9433\n",
      " 5502 1903 1634 5125 1192 3996 1420 1019 6420 3367 5342 1635 1154 4521\n",
      " 1962 4449 5709 3478 1884 9566 1951 2625 5550 1152 2774 1592 4936 6746\n",
      " 1864  417 1952 5917 8787 1168 2084 8759 2817 6421 2671 7927 3786 1515\n",
      " 8063 1321]\n",
      "[9562 7369 3518 1220 1836 8549  916 8558 2431 9095 7246 4840 1321 7252\n",
      " 5492 3556 8232 4379  847 8090 2253 1296 8141 2710 1635 7863 9195 2943\n",
      " 9905 2899 2859 3367 9812 2625 1169 3743 3039 5929 3760 1127 6360 6119\n",
      " 3543 1707 3478 4521 4990 2978 2102 1192 3298 3996 2513 4043 6602 1592\n",
      " 9574 5743 3384 2817 4381 5114 1634 4449 3520 1962 7867 1019 5342 5709\n",
      " 3967 7472 6757 6259 9888 1233 7389 3227 9799 6060 1152 5502 3305 7218\n",
      " 1168 7580  594 8063 1951 1903 9584 2171 8750 8416 3138 6648 5550 9274\n",
      " 2755 2084]\n"
     ]
    }
   ],
   "source": [
    "print(neighbours[1][1])\n",
    "print(neighbours_enc_r[1][1])\n",
    "print(neighbours_enc[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5659 3866 4539 9007 3156 5426 8254 7416 2810 7170 8665 4592 7607 9120\n",
      " 2104 3907 9001 5989 4673  809 9010 2667 3562  550 9852 4952 9353 4845\n",
      " 6625 6338 7960 7815 6270 4117 3190 7049 5004 7508 8122 9643 5705 9979\n",
      " 2768 5615 1129 3729 5851 9577 6418 8771 8180 5091 2869 5822  851 3390\n",
      " 4989 3643 2922 2180 4755  526 2306 5258 8717 7316 9763  853 7053 7792\n",
      " 7662 1940 5715 1921 9533 3685 6986 7652 7791 8501 9889 7991 6579 8076\n",
      " 7967 9397  812 2031 7604 7720  512 8862 7256 2341 2261 6359 6807 4944\n",
      " 1207 8165]\n",
      "[9007  550 5659 1129 4539 7416 5426 9577  809 9001 3156 3866 6338 9010\n",
      " 5989 8254 4592 7607 2104 2810 4952 9852 3907 8180 6625 2869 7049 3729\n",
      " 8665  853 2306 3562 2922 3190 6270 7508 2667 9120 3643 5615 1787 8717\n",
      " 7815 9353 8076 5237 7610 7170 9979  851 5091 8565 7662 5469 1921 7960\n",
      " 8496 1940 2180 3390 4845 4117 5258 2391   23 5004 6807 1818 4673 7316\n",
      " 5851 5241 7792  512 7967 8122 4989 8771 2031 4755 9763 1810  494 5272\n",
      "  660 5014 2768 1466 7616 9193  812 5368 1207  526 5571 4809 5715 8165\n",
      " 7791 2485]\n",
      "[9007  550 1129 5659 5989 7416 3866 6625 4539 2869 3156 4952 6338  809\n",
      " 8665 5426 2810 9852 9120 4673 4592 2667 7607 9001 4755 8771 9979 5705\n",
      " 2104 3190 9010 3390 5237 4845 8565 2306 8180 1822 8717 3562 9643 7662\n",
      " 2768 3855 7792 7170 8254 9577 3643 3907 7049 5615 2031 9397 1787 9889\n",
      " 6807 8122 6270 5004 7791 6986 5469 1207 1921 7508 2922 5272  756 2391\n",
      " 9353  487 7316 1940 2897  512 4516 4884 5258 3729  853   23 2261 4989\n",
      " 1013 5851 7967 3475 4809 1810 5822 2180 4117 2485 3132 5091 3948 5241\n",
      " 8656 7960]\n"
     ]
    }
   ],
   "source": [
    "print(neighbours[1][2])\n",
    "print(neighbours_enc_r[1][2])\n",
    "print(neighbours_enc[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.64767020424492\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def compare_list_order(list_a, list_b):\n",
    "    error = 0\n",
    "    \n",
    "    for a_index, a_content in enumerate(list_a):\n",
    "        try:\n",
    "            b_index = list_b.index(a_content)\n",
    "            error += math.fabs(a_index - b_index)\n",
    "        except ValueError:\n",
    "            error += len(list_a)\n",
    "    return error / len(list_a)\n",
    "\n",
    "\n",
    "overall_error = 0\n",
    "\n",
    "for image_idx, image_neighbours in enumerate(neighbours[1]):\n",
    "    overall_error += compare_list_order(list(image_neighbours), list(neighbours_enc[1][image_idx]))      \n",
    "\n",
    "print(overall_error / (len(neighbours[1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (image_processing)",
   "language": "python",
   "name": "pycharm-98d2f03d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}